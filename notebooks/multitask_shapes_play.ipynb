{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4607ae",
   "metadata": {},
   "source": [
    "# Multitask Shapes – interactive play  \n",
    "  \n",
    "This notebook lets you **play the customised “Multitask Shapes” environment** that you pasted.  \n",
    "At each step you’ll be asked for an action:\n",
    "\n",
    "| index | meaning  |\n",
    "|-------|----------|\n",
    "| 0     | **UP**   |\n",
    "| 1     | **DOWN** |\n",
    "| 2     | **LEFT** |\n",
    "| 3     | **RIGHT**|\n",
    "| 4     | **PICK** |\n",
    "| 5     | **DROP** |\n",
    "\n",
    "The notebook will  \n",
    "* execute the action,  \n",
    "* print the new reward & raw observation, and  \n",
    "* display the rendered frame.\n",
    "\n",
    "> **Prerequisites**  \n",
    "> * `shapes.py`, `multitask_shapes.py`, `utils.py`, the `assets/` folder and your YAML hyper‑parameter file must be provided.\n",
    "> * Python ≥ 3.9 with the packages in the first code‑cell installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2be1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# (Optional) install runtime dependencies\n",
    "# ------------------------------------------------------------\n",
    "# If you are missing any of these packages, remove the leading\n",
    "# '#' and run the cell once.\n",
    "#\n",
    "# !pip install -q gymnasium numpy opencv-python-headless matplotlib pyyaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faab382f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djordje/miniconda3/envs/rlexp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Imports & utility helpers\n",
    "# ------------------------------------------------------------\n",
    "import os, yaml, numpy as np, cv2, matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Adjust the import below if your python file has a different name\n",
    "from envs.shapes.multitask_shapes import MultitaskShapes, ShapesPositionFactory, ShapesAttrCombFactory\n",
    "from utils import setup_artefact_paths\n",
    "\n",
    "# Helper to display a rendered frame inline\n",
    "def show_frame(img):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    # convert BGR (OpenCV) ➜ RGB (matplotlib)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3338a57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready ✔\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Load hyper‑parameters & create the environment\n",
    "# ------------------------------------------------------------\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "# Fill yaml_path as desired, the rest should work as is.\n",
    "yaml_path = os.path.join(parent_dir, \"envs\", \"shapes\", \"configs\", \"shapes.yaml\")\n",
    "\n",
    "script_path = os.path.join(os.getcwd(), 'multitask_shapes_play.ipynb')\n",
    "store_path, _ = setup_artefact_paths(script_path)\n",
    "\n",
    "with open(yaml_path, 'r') as f:\n",
    "    hparams = yaml.safe_load(f)\n",
    "\n",
    "hparams = hparams[\"environment\"] if \"environment\" in hparams else hparams\n",
    "relevant_feature_index = 1 + int(hparams[\"goal_channel\"])\n",
    "\n",
    "env = ShapesAttrCombFactory(\n",
    "    hparams=hparams,\n",
    "    store_path=store_path\n",
    ").get_env(set_id=\"TRAIN\")\n",
    "obs_type = hparams[\"obs_type\"]\n",
    "print('Environment ready ✔')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450011d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Return so far: 0\n",
      "Current observation: [3 3 1 1 6 2 5 5 2 1 6 2]\n",
      "Instruction: Go to blue key.\n",
      "Choose action – 0:UP  1:DOWN  2:LEFT  3:RIGHT  4:PICK UP  5:DROP OFF\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# -------- environment step ------------\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m next_obs, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# update bookkeeping\u001b[39;00m\n\u001b[1;32m     44\u001b[0m last_reward \u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[0;32m~/dev/rlexp/envs/shapes/multitask_shapes.py:227\u001b[0m, in \u001b[0;36mMultitaskShapes.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m--> 227\u001b[0m     _, reward, is_terminal, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs, reward, is_terminal, truncated, info\n",
      "File \u001b[0;32m~/dev/rlexp/envs/shapes/shapes.py:381\u001b[0m, in \u001b[0;36mShapesGoto.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# Superclass will perform the agent movement but will not do any of the additional actions\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# or provide sensible reward\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m     obs, _, _, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     confounder_locations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objects \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_goal\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m obj \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_goal\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m    384\u001b[0m     is_terminal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/rlexp/envs/shapes/shapes.py:262\u001b[0m, in \u001b[0;36mShapes.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m    254\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Perform an action in the environment. Actions are as follows:\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m        - 0: go up\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m        - 1: go down\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m        - 5: drop #not used for now\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_movement\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    264\u001b[0m     info \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/dev/rlexp/envs/shapes/shapes.py:243\u001b[0m, in \u001b[0;36mShapes._movement\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    241\u001b[0m         action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrng\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 243\u001b[0m agent_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agent_location) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_to_direction\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grid[agent_location] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agent_location \u001b[38;5;241m=\u001b[39m agent_location\n",
      "\u001b[0;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": [
    "# ---- initial reset ----\n",
    "obs, _ = env.reset()\n",
    "step = 0\n",
    "total_reward = 0\n",
    "last_reward = None          # stores reward from previous step\n",
    "terminated = truncated = False\n",
    "\n",
    "while not (terminated or truncated):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # -------- show current frame ----------\n",
    "    frame = env.render_frame()\n",
    "    show_frame(frame)\n",
    "\n",
    "    # -------- show textual info -----------\n",
    "    print(f\"Step: {step}\")\n",
    "    print(f\"Return so far: {total_reward}\")\n",
    "    if last_reward is not None:\n",
    "        print(f\"Reward from previous action: {last_reward}\")\n",
    "    if obs_type == \"box\":\n",
    "        print(f\"Current observation: {obs['features'][relevant_feature_index:, 1, 1]}\")\n",
    "        print(f\"{obs['features'][0,:,:]}\")\n",
    "        print(f\"{obs['features'][1,:,:]}\")\n",
    "    else:\n",
    "        print(f\"Current observation: {obs['features']}\")\n",
    "\n",
    "    print(f\"Instruction: {obs['instr']}\")\n",
    "    print(\"Choose action – 0:UP  1:DOWN  2:LEFT  3:RIGHT  4:PICK UP  5:DROP OFF\")\n",
    "\n",
    "    # -------- get action ------------------\n",
    "    try:\n",
    "        action = int(input(\"Your action index: \").strip())\n",
    "        if action not in range(6):\n",
    "            raise ValueError\n",
    "    except ValueError:\n",
    "        print(\"❌  Please enter an integer 0‑5.\")\n",
    "        time.sleep(1)        # let the user read the error\n",
    "        continue\n",
    "\n",
    "    # -------- environment step ------------\n",
    "    next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "    # update bookkeeping\n",
    "    last_reward = reward\n",
    "    total_reward += reward\n",
    "    obs = next_obs\n",
    "    step += 1\n",
    "\n",
    "# final display\n",
    "clear_output(wait=True)\n",
    "frame = env.render_frame()\n",
    "show_frame(frame)\n",
    "print(\"Episode finished.\")\n",
    "if obs_type == \"box\":\n",
    "    print(obs['features'][relevant_feature_index:, 1, 1])\n",
    "else:\n",
    "    print(f\"Current observation: {obs['features']}\")\n",
    "print(f\"Total steps: {step}   Return: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc56dd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'shape': 'ball', 'colour': 'red', 'loc': (1, 1)},\n",
       " {'shape': 'ball', 'colour': 'red', 'loc': (5, 5)},\n",
       " {'shape': 'ball', 'colour': 'blue', 'loc': (1, 1)},\n",
       " {'shape': 'ball', 'colour': 'blue', 'loc': (5, 5)},\n",
       " {'shape': 'ball', 'colour': 'green', 'loc': (1, 1)},\n",
       " {'shape': 'ball', 'colour': 'green', 'loc': (5, 5)},\n",
       " {'shape': 'ball', 'colour': 'yellow', 'loc': (5, 5)},\n",
       " {'shape': 'triangle', 'colour': 'red', 'loc': (1, 1)},\n",
       " {'shape': 'triangle', 'colour': 'red', 'loc': (5, 5)},\n",
       " {'shape': 'triangle', 'colour': 'blue', 'loc': (1, 1)},\n",
       " {'shape': 'triangle', 'colour': 'blue', 'loc': (5, 5)},\n",
       " {'shape': 'triangle', 'colour': 'green', 'loc': (1, 1)},\n",
       " {'shape': 'triangle', 'colour': 'green', 'loc': (5, 5)},\n",
       " {'shape': 'triangle', 'colour': 'yellow', 'loc': (1, 1)},\n",
       " {'shape': 'triangle', 'colour': 'yellow', 'loc': (5, 5)},\n",
       " {'shape': 'square', 'colour': 'red', 'loc': (1, 1)},\n",
       " {'shape': 'square', 'colour': 'red', 'loc': (5, 5)},\n",
       " {'shape': 'square', 'colour': 'blue', 'loc': (1, 1)},\n",
       " {'shape': 'square', 'colour': 'blue', 'loc': (5, 5)},\n",
       " {'shape': 'square', 'colour': 'green', 'loc': (5, 5)},\n",
       " {'shape': 'square', 'colour': 'yellow', 'loc': (1, 1)},\n",
       " {'shape': 'square', 'colour': 'yellow', 'loc': (5, 5)},\n",
       " {'shape': 'diamond', 'colour': 'red', 'loc': (5, 5)},\n",
       " {'shape': 'diamond', 'colour': 'blue', 'loc': (1, 1)},\n",
       " {'shape': 'diamond', 'colour': 'blue', 'loc': (5, 5)},\n",
       " {'shape': 'diamond', 'colour': 'green', 'loc': (1, 1)},\n",
       " {'shape': 'diamond', 'colour': 'green', 'loc': (5, 5)},\n",
       " {'shape': 'diamond', 'colour': 'yellow', 'loc': (1, 1)},\n",
       " {'shape': 'diamond', 'colour': 'yellow', 'loc': (5, 5)},\n",
       " {'shape': 'star', 'colour': 'red', 'loc': (1, 1)},\n",
       " {'shape': 'star', 'colour': 'red', 'loc': (5, 5)},\n",
       " {'shape': 'star', 'colour': 'blue', 'loc': (5, 5)},\n",
       " {'shape': 'star', 'colour': 'green', 'loc': (1, 1)},\n",
       " {'shape': 'star', 'colour': 'green', 'loc': (5, 5)},\n",
       " {'shape': 'star', 'colour': 'yellow', 'loc': (1, 1)},\n",
       " {'shape': 'star', 'colour': 'yellow', 'loc': (5, 5)},\n",
       " {'shape': 'key', 'colour': 'red', 'loc': (1, 1)},\n",
       " {'shape': 'key', 'colour': 'red', 'loc': (5, 5)},\n",
       " {'shape': 'key', 'colour': 'blue', 'loc': (1, 1)},\n",
       " {'shape': 'key', 'colour': 'blue', 'loc': (5, 5)},\n",
       " {'shape': 'key', 'colour': 'green', 'loc': (1, 1)},\n",
       " {'shape': 'key', 'colour': 'green', 'loc': (5, 5)},\n",
       " {'shape': 'key', 'colour': 'yellow', 'loc': (1, 1)},\n",
       " {'shape': 'key', 'colour': 'yellow', 'loc': (5, 5)}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.goal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510b9c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlexp",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
