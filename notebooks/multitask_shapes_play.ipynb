{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4607ae",
   "metadata": {},
   "source": [
    "# Multitask Shapes – interactive play  \n",
    "  \n",
    "This notebook lets you **play the customised “Multitask Shapes” environment** that you pasted.  \n",
    "At each step you’ll be asked for an action:\n",
    "\n",
    "| index | meaning  |\n",
    "|-------|----------|\n",
    "| 0     | **UP**   |\n",
    "| 1     | **DOWN** |\n",
    "| 2     | **LEFT** |\n",
    "| 3     | **RIGHT**|\n",
    "| 4     | **PICK** |\n",
    "| 5     | **DROP** |\n",
    "\n",
    "The notebook will  \n",
    "* execute the action,  \n",
    "* print the new reward & raw observation, and  \n",
    "* display the rendered frame.\n",
    "\n",
    "> **Prerequisites**  \n",
    "> * `shapes.py`, `multitask_shapes.py`, `utils.py`, the `assets/` folder and your YAML hyper‑parameter file must be provided.\n",
    "> * Python ≥ 3.9 with the packages in the first code‑cell installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2be1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# (Optional) install runtime dependencies\n",
    "# ------------------------------------------------------------\n",
    "# If you are missing any of these packages, remove the leading\n",
    "# '#' and run the cell once.\n",
    "#\n",
    "# !pip install -q gymnasium numpy opencv-python-headless matplotlib pyyaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab382f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djordje/miniconda3/envs/rlexp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Imports & utility helpers\n",
    "# ------------------------------------------------------------\n",
    "import os, yaml, numpy as np, cv2, matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Adjust the import below if your python file has a different name\n",
    "from envs.shapes.multitask_shapes import MultitaskShapes, ShapesPositionFactory, ShapesAttrCombFactory\n",
    "from utils import setup_artefact_paths\n",
    "\n",
    "# Helper to display a rendered frame inline\n",
    "def show_frame(img):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    # convert BGR (OpenCV) ➜ RGB (matplotlib)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338a57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready ✔\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Load hyper‑parameters & create the environment\n",
    "# ------------------------------------------------------------\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "# Fill yaml_path as desired, the rest should work as is.\n",
    "yaml_path = os.path.join(parent_dir, \"envs\", \"shapes\", \"configs\", \"shapes.yaml\")\n",
    "\n",
    "script_path = os.path.join(os.getcwd(), 'multitask_shapes_play.ipynb')\n",
    "store_path, _ = setup_artefact_paths(script_path)\n",
    "\n",
    "with open(yaml_path, 'r') as f:\n",
    "    hparams = yaml.safe_load(f)\n",
    "\n",
    "hparams = hparams[\"environment\"] if \"environment\" in hparams else hparams\n",
    "relevant_feature_index = 1 + int(hparams[\"goal_channel\"])\n",
    "\n",
    "env = ShapesAttrCombFactory(\n",
    "    hparams=hparams,\n",
    "    store_path=store_path\n",
    ").get_env(set_id=\"TRAIN\")\n",
    "obs_type = hparams[\"obs_type\"]\n",
    "print('Environment ready ✔')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450011d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Return so far: 0\n",
      "Current observation: [4 4 1 1 1 4 4 8 4 1 4 1]\n",
      "Instruction: Go to red diamond.\n",
      "Choose action – 0:UP  1:DOWN  2:LEFT  3:RIGHT  4:PICK UP  5:DROP OFF\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# -------- environment step ------------\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m next_obs, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# update bookkeeping\u001b[39;00m\n\u001b[1;32m     44\u001b[0m last_reward \u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[0;32m~/dev/rlexp/envs/shapes/multitask_shapes.py:181\u001b[0m, in \u001b[0;36mMultitaskShapes.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m--> 181\u001b[0m     _, reward, is_terminal, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs, reward, is_terminal, truncated, info\n",
      "File \u001b[0;32m~/dev/rlexp/envs/shapes/shapes.py:379\u001b[0m, in \u001b[0;36mShapesGoto.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# Superclass will perform the agent movement but will not do any of the additional actions\u001b[39;00m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# or provide sensible reward\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     obs, _, _, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     confounder_locations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objects \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_goal\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m obj \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_goal\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m    382\u001b[0m     is_terminal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/rlexp/envs/shapes/shapes.py:260\u001b[0m, in \u001b[0;36mShapes.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m    252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Perform an action in the environment. Actions are as follows:\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m        - 0: go up\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m        - 1: go down\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m        - 5: drop #not used for now\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_movement\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    262\u001b[0m     info \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/dev/rlexp/envs/shapes/shapes.py:241\u001b[0m, in \u001b[0;36mShapes._movement\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    239\u001b[0m         action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrng\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 241\u001b[0m agent_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agent_location) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_to_direction\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grid[agent_location] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agent_location \u001b[38;5;241m=\u001b[39m agent_location\n",
      "\u001b[0;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": [
    "# ---- initial reset ----\n",
    "obs, _ = env.reset()\n",
    "step = 0\n",
    "total_reward = 0\n",
    "last_reward = None          # stores reward from previous step\n",
    "terminated = truncated = False\n",
    "\n",
    "while not (terminated or truncated):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # -------- show current frame ----------\n",
    "    frame = env.render_frame()\n",
    "    show_frame(frame)\n",
    "\n",
    "    # -------- show textual info -----------\n",
    "    print(f\"Step: {step}\")\n",
    "    print(f\"Return so far: {total_reward}\")\n",
    "    if last_reward is not None:\n",
    "        print(f\"Reward from previous action: {last_reward}\")\n",
    "    if obs_type == \"box\":\n",
    "        print(f\"Current observation: {obs['features'][relevant_feature_index:, 1, 1]}\")\n",
    "        print(f\"{obs['features'][0,:,:]}\")\n",
    "        print(f\"{obs['features'][1,:,:]}\")\n",
    "    else:\n",
    "        print(f\"Current observation: {obs['features']}\")\n",
    "\n",
    "    print(f\"Instruction: {obs['instr']}\")\n",
    "    print(\"Choose action – 0:UP  1:DOWN  2:LEFT  3:RIGHT  4:PICK UP  5:DROP OFF\")\n",
    "\n",
    "    # -------- get action ------------------\n",
    "    try:\n",
    "        action = int(input(\"Your action index: \").strip())\n",
    "        if action not in range(6):\n",
    "            raise ValueError\n",
    "    except ValueError:\n",
    "        print(\"❌  Please enter an integer 0‑5.\")\n",
    "        time.sleep(1)        # let the user read the error\n",
    "        continue\n",
    "\n",
    "    # -------- environment step ------------\n",
    "    next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "    # update bookkeeping\n",
    "    last_reward = reward\n",
    "    total_reward += reward\n",
    "    obs = next_obs\n",
    "    step += 1\n",
    "\n",
    "# final display\n",
    "clear_output(wait=True)\n",
    "frame = env.render_frame()\n",
    "show_frame(frame)\n",
    "print(\"Episode finished.\")\n",
    "if obs_type == \"box\":\n",
    "    print(obs['features'][relevant_feature_index:, 1, 1])\n",
    "else:\n",
    "    print(f\"Current observation: {obs['features']}\")\n",
    "print(f\"Total steps: {step}   Return: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc56dd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlexp",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
