{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4607ae",
   "metadata": {},
   "source": [
    "# Multitask Shapes – interactive play  \n",
    "  \n",
    "This notebook lets you **play the customised “Multitask Shapes” environment** that you pasted.  \n",
    "At each step you’ll be asked for an action:\n",
    "\n",
    "| index | meaning  |\n",
    "|-------|----------|\n",
    "| 0     | **UP**   |\n",
    "| 1     | **DOWN** |\n",
    "| 2     | **LEFT** |\n",
    "| 3     | **RIGHT**|\n",
    "| 4     | **PICK** |\n",
    "| 5     | **DROP** |\n",
    "\n",
    "The notebook will  \n",
    "* execute the action,  \n",
    "* print the new reward & raw observation, and  \n",
    "* display the rendered frame.\n",
    "\n",
    "> **Prerequisites**  \n",
    "> * `shapes.py`, `multitask_shapes.py`, `utils.py`, the `assets/` folder and your YAML hyper‑parameter file must be provided.\n",
    "> * Python ≥ 3.9 with the packages in the first code‑cell installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2be1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# (Optional) install runtime dependencies\n",
    "# ------------------------------------------------------------\n",
    "# If you are missing any of these packages, remove the leading\n",
    "# '#' and run the cell once.\n",
    "#\n",
    "# !pip install -q gymnasium numpy opencv-python-headless matplotlib pyyaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faab382f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djordje/miniconda3/envs/rlexp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Imports & utility helpers\n",
    "# ------------------------------------------------------------\n",
    "import os, yaml, numpy as np, cv2, matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Adjust the import below if your python file has a different name\n",
    "from envs.shapes.multitask_shapes import MultitaskShapes, ShapesPositionFactory\n",
    "from utils import setup_artefact_paths\n",
    "\n",
    "# Helper to display a rendered frame inline\n",
    "def show_frame(img):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    # convert BGR (OpenCV) ➜ RGB (matplotlib)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3338a57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready ✔\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Load hyper‑parameters & create the environment\n",
    "# ------------------------------------------------------------\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "# Fill yaml_path as desired, the rest should work as is.\n",
    "yaml_path = os.path.join(parent_dir, \"envs\", \"shapes\", \"configs\", \"shapes.yaml\")\n",
    "\n",
    "script_path = os.path.join(os.getcwd(), 'multitask_shapes_play.ipynb')\n",
    "store_path, _ = setup_artefact_paths(script_path)\n",
    "\n",
    "with open(yaml_path, 'r') as f:\n",
    "    hparams = yaml.safe_load(f)\n",
    "\n",
    "hparams = hparams[\"environment\"] if \"environment\" in hparams else hparams\n",
    "relevant_feature_index = 1 + int(hparams[\"goal_channel\"])\n",
    "\n",
    "env = ShapesPositionFactory(\n",
    "    hparams=hparams,\n",
    "    store_path=store_path\n",
    ").get_env(set_id=\"TRAIN\")\n",
    "obs_type = hparams[\"obs_type\"]\n",
    "print('Environment ready ✔')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450011d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Return so far: 0\n",
      "Current observation: [3 5 2 6 1 3 1 1 4 4 1 3]\n",
      "Instruction: Go to green ball.\n",
      "Choose action – 0:UP  1:DOWN  2:LEFT  3:RIGHT  4:PICK UP  5:DROP OFF\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# -------- environment step ------------\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m next_obs, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# update bookkeeping\u001b[39;00m\n\u001b[1;32m     44\u001b[0m last_reward \u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[0;32m~/dev/rlexp/envs/shapes/multitask_shapes.py:177\u001b[0m, in \u001b[0;36mMultitaskShapes.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m--> 177\u001b[0m     _, reward, is_terminal, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs, reward, is_terminal, truncated, info\n",
      "File \u001b[0;32m~/dev/rlexp/envs/shapes/shapes.py:376\u001b[0m, in \u001b[0;36mShapesGoto.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# Superclass will perform the agent movement but will not do any of the additional actions\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# or provide sensible reward\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m     obs, _, _, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     confounder_locations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objects \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_goal\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m obj \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_goal\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m    379\u001b[0m     is_terminal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/rlexp/envs/shapes/shapes.py:257\u001b[0m, in \u001b[0;36mShapes.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m    249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Perform an action in the environment. Actions are as follows:\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m        - 0: go up\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m        - 1: go down\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m        - 5: drop #not used for now\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_movement\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    259\u001b[0m     info \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/dev/rlexp/envs/shapes/shapes.py:238\u001b[0m, in \u001b[0;36mShapes._movement\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    236\u001b[0m         action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrng\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 238\u001b[0m agent_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agent_location) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_to_direction\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grid[agent_location] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agent_location \u001b[38;5;241m=\u001b[39m agent_location\n",
      "\u001b[0;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": [
    "# ---- initial reset ----\n",
    "obs, _ = env.reset()\n",
    "step = 0\n",
    "total_reward = 0\n",
    "last_reward = None          # stores reward from previous step\n",
    "terminated = truncated = False\n",
    "\n",
    "while not (terminated or truncated):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # -------- show current frame ----------\n",
    "    frame = env.render_frame()\n",
    "    show_frame(frame)\n",
    "\n",
    "    # -------- show textual info -----------\n",
    "    print(f\"Step: {step}\")\n",
    "    print(f\"Return so far: {total_reward}\")\n",
    "    if last_reward is not None:\n",
    "        print(f\"Reward from previous action: {last_reward}\")\n",
    "    if obs_type == \"box\":\n",
    "        print(f\"Current observation: {obs['features'][relevant_feature_index:, 1, 1]}\")\n",
    "        print(f\"{obs['features'][0,:,:]}\")\n",
    "        print(f\"{obs['features'][1,:,:]}\")\n",
    "    else:\n",
    "        print(f\"Current observation: {obs['features']}\")\n",
    "\n",
    "    print(f\"Instruction: {obs['instr']}\")\n",
    "    print(\"Choose action – 0:UP  1:DOWN  2:LEFT  3:RIGHT  4:PICK UP  5:DROP OFF\")\n",
    "\n",
    "    # -------- get action ------------------\n",
    "    try:\n",
    "        action = int(input(\"Your action index: \").strip())\n",
    "        if action not in range(6):\n",
    "            raise ValueError\n",
    "    except ValueError:\n",
    "        print(\"❌  Please enter an integer 0‑5.\")\n",
    "        time.sleep(1)        # let the user read the error\n",
    "        continue\n",
    "\n",
    "    # -------- environment step ------------\n",
    "    next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "    # update bookkeeping\n",
    "    last_reward = reward\n",
    "    total_reward += reward\n",
    "    obs = next_obs\n",
    "    step += 1\n",
    "\n",
    "# final display\n",
    "clear_output(wait=True)\n",
    "frame = env.render_frame()\n",
    "show_frame(frame)\n",
    "print(\"Episode finished.\")\n",
    "if obs_type == \"box\":\n",
    "    print(obs['features'][relevant_feature_index:, 1, 1])\n",
    "else:\n",
    "    print(f\"Current observation: {obs['features']}\")\n",
    "print(f\"Total steps: {step}   Return: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc56dd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlexp",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
